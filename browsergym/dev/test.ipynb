{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-27T18:24:43.518748Z",
     "start_time": "2025-07-27T18:24:43.514072Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from bs4 import BeautifulSoup\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import os, sys\n",
    "project_root = os.path.abspath('/Users/subhojit/workspace/lcow_iclr2025/browsergym')\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "from dev.embedding_store import *\n",
    "from dev.sim_dim_gen import *"
   ],
   "outputs": [],
   "execution_count": 67
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size=7680, hidden_size=200):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, hidden_size)\n",
    "        self.layer2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.layer3 = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        x = self.layer3(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ],
   "id": "b91a4f6c5e792ccb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "trajectory_file_path = '/Users/subhojit/workspace/lcow_iclr2025/browsergym/workarena_seed_demo_iter_0.csv'\n",
    "df = pd.read_csv(trajectory_file_path)\n",
    "df.head()\n",
    "\n",
    "\n"
   ],
   "id": "9795cab152175ca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import openai\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "openai.api_key = \"\"\n",
    "\n",
    "texts = [\n",
    "    \"WILBUR learns web navigation by in-context learning.\",\n",
    "    \"Language models can solve many real-world tasks.\",\n",
    "    \"Web agents must understand HTML structure.\"\n",
    "]\n",
    "\n",
    "embeddings = []\n",
    "for text in texts:\n",
    "    response = openai.embeddings.create(\n",
    "        model=\"text-embedding-3-large\",\n",
    "        input=text\n",
    "    )\n",
    "    emb = response.data[0].embedding\n",
    "    embeddings.append(emb)\n",
    "\n",
    "embeddings = np.array(embeddings)\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "reduced_embeddings = pca.fit_transform(embeddings)\n",
    "\n",
    "print(\"Reduced shape:\", reduced_embeddings.shape)\n",
    "print(reduced_embeddings)\n",
    "\n",
    "\n"
   ],
   "id": "aa0c3be70d03ca59",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "15c16b48c03e5dd5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"osunlp/Mind2Web\")"
   ],
   "id": "4da15a9f5165126c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sample = ds['train'][0]\n",
    "print(len(ds['train']))\n",
    "action_rep = sample['action_reprs']\n",
    "# print(\"Action representation: \", action_rep)\n",
    "goal = sample[\"confirmed_task\"]\n",
    "# print(\"Goal: \", goal)\n",
    "actions = sample['actions']\n",
    "# print(\"Actions: \", actions)\n",
    "init_dom = actions[0]['cleaned_html']\n",
    "# print('init dom: ', init_dom)\n"
   ],
   "id": "4192e3e73bd3c23c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import json\n",
    "count = 0\n",
    "res = []\n",
    "for elem in ds['train']:\n",
    "    acts = elem['actions']\n",
    "    for a in acts:\n",
    "        res.append({'action': a['operation'], 'dom': a['cleaned_html']})\n",
    "        count += 1\n",
    "    if count > 100:\n",
    "        break\n",
    "\n",
    "with open('training_data_new.json', 'w') as f:\n",
    "    json.dump(res, f, indent=2)\n",
    "\n"
   ],
   "id": "8fa88b49300f50b6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import tiktoken\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "encoding = tiktoken.encoding_for_model(\"text-embedding-3-large\")\n",
    "\n",
    "with open(\"training_data_new_aug.json\", 'r') as f:\n",
    "    tasks = json.load(f)\n",
    "\n",
    "def extract_text_from_html(html: str) -> str:\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    for tag in soup([\"script\", \"style\", \"noscript\"]):\n",
    "        tag.decompose()\n",
    "    return soup.get_text(separator=\" \", strip=True)\n",
    "\n",
    "for task in tasks:\n",
    "    text = task['dom']\n",
    "    ex_text = extract_text_from_html(text)\n",
    "    num_tokens = len(encoding.encode(ex_text))\n",
    "    task['ext_dom'] = ex_text\n",
    "\n",
    "with open('training_data_new_aug_1.json', 'w') as f:\n",
    "    json.dump(tasks, f, indent=2)\n"
   ],
   "id": "6a57eeda9679012a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T18:03:09.942544Z",
     "start_time": "2025-07-27T18:03:09.516972Z"
    }
   },
   "cell_type": "code",
   "source": "cache = load_cache()",
   "id": "97ac46548eababc2",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T18:47:04.709412Z",
     "start_time": "2025-07-27T18:47:04.598312Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(\"training_data_new_aug_1.json\", 'r') as f:\n",
    "    tasks = json.load(f)\n",
    "\n",
    "input = []\n",
    "target = []\n",
    "for task in tasks:\n",
    "    act = task['nl_action']\n",
    "    ext_dom = task['ext_dom']\n",
    "    act_emb = get_embedding(act, cache)\n",
    "    ext_emb = get_embedding(ext_dom, cache)\n",
    "    sim_emb = get_embedding(get_sim(act), cache)\n",
    "    opp_emb = get_embedding(get_opp(act), cache)\n",
    "    sim_con = np.concatenate((act_emb, ext_emb, sim_emb), axis=0)\n",
    "    input.append(sim_con)\n",
    "    target.append(1)\n",
    "    opp_con = np.concatenate((act_emb, ext_emb, opp_emb), axis=0)\n",
    "    input.append(opp_con)\n",
    "    target.append(0)\n",
    "\n",
    "X = np.array(input)\n",
    "y = np.array(target)\n"
   ],
   "id": "36f224c01d2486c5",
   "outputs": [],
   "execution_count": 84
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T18:47:06.864532Z",
     "start_time": "2025-07-27T18:47:06.861872Z"
    }
   },
   "cell_type": "code",
   "source": "X.shape, y.shape",
   "id": "552b82b51020721c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((202, 9216), (202,))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 85
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T18:21:44.346969Z",
     "start_time": "2025-07-27T18:21:44.266482Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "#\n",
    "# pca = PCA(n_components=202)\n",
    "# X_reduced = pca.fit_transform(X)"
   ],
   "id": "ad9351544594d374",
   "outputs": [],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T18:47:19.429324Z",
     "start_time": "2025-07-27T18:47:19.426537Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_reduced = X\n",
    "X_reduced.shape"
   ],
   "id": "e0ee46e29977d7d4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(202, 9216)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 86
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T18:47:25.620437Z",
     "start_time": "2025-07-27T18:47:25.603874Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = \"mps\"\n",
    "\n",
    "model = MLP(input_size=X_reduced.shape[1], hidden_size=200).to(device)\n",
    "\n",
    "X_tensor = torch.tensor(X_reduced, dtype=torch.float32).to(device)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32).view(-1, 1).to(device)\n",
    "\n",
    "dataset = TensorDataset(X_tensor, y_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ],
   "id": "c65571b1bade368a",
   "outputs": [],
   "execution_count": 87
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T18:47:27.863989Z",
     "start_time": "2025-07-27T18:47:27.861070Z"
    }
   },
   "cell_type": "code",
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n"
   ],
   "id": "5c8e641f805bff62",
   "outputs": [],
   "execution_count": 88
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T18:47:30.214558Z",
     "start_time": "2025-07-27T18:47:29.126412Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for epoch in range(50):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for X_batch, y_batch in dataloader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X_batch)\n",
    "        loss = criterion(output, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss / len(dataloader):.4f}\")"
   ],
   "id": "b159b51e44a63419",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.6697\n",
      "Epoch 2, Loss: 0.5186\n",
      "Epoch 3, Loss: 0.2699\n",
      "Epoch 4, Loss: 0.1244\n",
      "Epoch 5, Loss: 0.0833\n",
      "Epoch 6, Loss: 0.0604\n",
      "Epoch 7, Loss: 0.0402\n",
      "Epoch 8, Loss: 0.0319\n",
      "Epoch 9, Loss: 0.0203\n",
      "Epoch 10, Loss: 0.0151\n",
      "Epoch 11, Loss: 0.0109\n",
      "Epoch 12, Loss: 0.0058\n",
      "Epoch 13, Loss: 0.0052\n",
      "Epoch 14, Loss: 0.0033\n",
      "Epoch 15, Loss: 0.0025\n",
      "Epoch 16, Loss: 0.0020\n",
      "Epoch 17, Loss: 0.0020\n",
      "Epoch 18, Loss: 0.0017\n",
      "Epoch 19, Loss: 0.0014\n",
      "Epoch 20, Loss: 0.0013\n",
      "Epoch 21, Loss: 0.0012\n",
      "Epoch 22, Loss: 0.0010\n",
      "Epoch 23, Loss: 0.0009\n",
      "Epoch 24, Loss: 0.0008\n",
      "Epoch 25, Loss: 0.0007\n",
      "Epoch 26, Loss: 0.0006\n",
      "Epoch 27, Loss: 0.0005\n",
      "Epoch 28, Loss: 0.0005\n",
      "Epoch 29, Loss: 0.0005\n",
      "Epoch 30, Loss: 0.0004\n",
      "Epoch 31, Loss: 0.0004\n",
      "Epoch 32, Loss: 0.0003\n",
      "Epoch 33, Loss: 0.0003\n",
      "Epoch 34, Loss: 0.0003\n",
      "Epoch 35, Loss: 0.0002\n",
      "Epoch 36, Loss: 0.0002\n",
      "Epoch 37, Loss: 0.0002\n",
      "Epoch 38, Loss: 0.0002\n",
      "Epoch 39, Loss: 0.0002\n",
      "Epoch 40, Loss: 0.0002\n",
      "Epoch 41, Loss: 0.0001\n",
      "Epoch 42, Loss: 0.0002\n",
      "Epoch 43, Loss: 0.0002\n",
      "Epoch 44, Loss: 0.0001\n",
      "Epoch 45, Loss: 0.0001\n",
      "Epoch 46, Loss: 0.0001\n",
      "Epoch 47, Loss: 0.0001\n",
      "Epoch 48, Loss: 0.0001\n",
      "Epoch 49, Loss: 0.0001\n",
      "Epoch 50, Loss: 0.0001\n"
     ]
    }
   ],
   "execution_count": 89
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T18:28:16.465974Z",
     "start_time": "2025-07-27T18:28:16.234861Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    preds = model(X_tensor)\n",
    "    preds_binary = (preds > 0.5).float()\n",
    "    accuracy = (preds_binary == y_tensor).float().mean()\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")"
   ],
   "id": "f970dea3237fed08",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0000\n"
     ]
    }
   ],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T18:47:35.173292Z",
     "start_time": "2025-07-27T18:47:35.155083Z"
    }
   },
   "cell_type": "code",
   "source": "torch.save(model.state_dict(), \"mlp_model.pt\")",
   "id": "eeb802b80895363d",
   "outputs": [],
   "execution_count": 90
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T18:47:36.903892Z",
     "start_time": "2025-07-27T18:47:36.890714Z"
    }
   },
   "cell_type": "code",
   "source": "model.load_state_dict(torch.load(\"mlp_model.pt\", map_location=device))",
   "id": "46b0b733b63df3c7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 91
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T18:54:46.089743Z",
     "start_time": "2025-07-27T18:54:46.047335Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(\"training_data_new_aug_1.json\", 'r') as f:\n",
    "    tasks = json.load(f)\n",
    "\n",
    "t = tasks[0]\n",
    "act = t['nl_action']\n",
    "ext_dom = t['ext_dom']\n",
    "act_emb = get_embedding(act, cache)\n",
    "ext_emb = get_embedding(ext_dom, cache)\n",
    "sim_emb = get_embedding(get_sim(act), cache)\n",
    "opp_emb = get_embedding(get_opp(act), cache)\n",
    "sim_con = np.concatenate((act_emb, ext_emb, sim_emb), axis=0)\n",
    "opp_con = np.concatenate((act_emb, ext_emb, opp_emb), axis=0)\n",
    "\n",
    "input_tensor = torch.tensor(sim_con, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(input_tensor)\n",
    "    prediction = (output > 0.5).float()\n",
    "\n",
    "print(f\"Predicted probability: {output.item():.8f}\")\n",
    "print(f\"Predicted class: {int(prediction.item())}\")"
   ],
   "id": "84e29acd7690bcfa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted probability: 0.99889827\n",
      "Predicted class: 1\n"
     ]
    }
   ],
   "execution_count": 100
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "207c115512d9fe05"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
